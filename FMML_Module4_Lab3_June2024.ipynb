{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saranyatripurari/FMML_LABS_PROJECTS/blob/main/FMML_Module4_Lab3_June2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FOUNDATIONS OF MODERN MACHINE LEARNING, IIIT Hyderabad\n",
        "# Module 4: Perceptron and Gradient Descent\n",
        "## Lab 3: Gradient Descent\n",
        "\n",
        "Gradient descent is a very important algorithm to understand, as it underpins many of the more advanced algorithms used in Machine Learning and Deep Learning.\n",
        "\n",
        "A brief overview of the algorithm is\n",
        "\n",
        "\n",
        "*   start with a random initialization of the solution.\n",
        "*   incrementally change the solution by moving in the direction of negative gradient of the objective function.\n",
        "*   repeat the previous step until some convergence criteria is met.\n",
        "\n",
        "The key equation for change in weight is:\n",
        "$$w^{k+1} \\leftarrow w^k - \\eta \\Delta J$$\n",
        "\n",
        "In this lab, we will discuss stochastic gradient descent, mini-batch gradient descent and batch gradient descent.\n"
      ],
      "metadata": {
        "id": "XYxxkQg6xCjD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr-MnaGs7JmZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ob_zZms7VOu"
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Kix4bcChiy"
      },
      "source": [
        "# Creating the Data\n",
        "\n",
        "Let's generate some data with:\n",
        "\\begin{equation} y_0= 4 \\end{equation}\n",
        "\\begin{equation} y_1= 3 \\end{equation}\n",
        "\n",
        "and also add some noise to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtAS7eFZ9hX6"
      },
      "source": [
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD95NaF-CxM-"
      },
      "source": [
        "Let's also plot the data we just created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IiEP4BQ7Wja"
      },
      "source": [
        "plt.plot(X, y, 'b.')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y', rotation=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScwxpouoDDyZ"
      },
      "source": [
        "## Cost Function\n",
        "\n",
        "The equation for calculating cost function is as shown below. The cost function is only for linear regression. For other algorithms, the cost function will be different and the gradients would have to be derived from the cost functions\n",
        "\n",
        "\\begin{equation}\n",
        "J(y_{pred}) = \\frac{1}{2} m \\sum_{i=1}^{m} (h(y_{pred})^{(i)} - y^{(i)})^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUeTUAXH7ZaV"
      },
      "source": [
        "def cal_cost(y_pred, X, y):\n",
        "    '''\n",
        "    Calculates the cost for given X and Y.\n",
        "    y_pred = Vector of y_preds\n",
        "    X = Row of X's np.zeros((2, j))\n",
        "    y = Actual y's np.zeros((2, 1))\n",
        "\n",
        "    where:\n",
        "        j is the no of features\n",
        "    '''\n",
        "\n",
        "    m = len(y)\n",
        "\n",
        "    predictions = X.dot(y_pred)\n",
        "    cost = (1 / 2 * m) * np.sum(np.square(predictions - y))\n",
        "\n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcXqsVNpDbKC"
      },
      "source": [
        "## Gradients\n",
        "\n",
        "\\begin{equation}\n",
        "y_{pred_0}: = y_{pred_0} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(y_{pred}^{(i)} - y^{(i)}).X_0^{(i)})\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "y_{pred_1}: = y_{pred_1} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(y_{pred}^{(i)} - y^{(i)}).X_0^{(i)})\n",
        "\\end{equation}\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\\begin{equation}\n",
        "y_{pred_j}: = y_{pred_j} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(y_{pred}^{(i)} - y^{(i)}).X_0^{(i)})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwxBFXP88NBW"
      },
      "source": [
        "def gradient_descent(X, y, y_pred, learning_rate=0.01, iterations=100):\n",
        "    '''\n",
        "    X = Matrix of X with added bias units\n",
        "    y = Vector of Y\n",
        "    y_pred = Vector of y_preds np.random.randn(j, 1)\n",
        "    learning_rate\n",
        "    iterations = no of iterations\n",
        "\n",
        "    Returns the final y_pred vector and array of cost history over no of iterations\n",
        "    '''\n",
        "\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "    y_pred_history = np.zeros((iterations, 2))\n",
        "\n",
        "    for it in range(iterations):\n",
        "        prediction = np.dot(X, y_pred)\n",
        "        y_pred = y_pred - (1 / m) * learning_rate * (X.T.dot((prediction - y)))\n",
        "        y_pred_history[it,:] = y_pred.T\n",
        "        cost_history[it]  = cal_cost(y_pred, X, y)\n",
        "\n",
        "    return y_pred, cost_history, y_pred_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iSohSB2EtK1"
      },
      "source": [
        "Let's do 1000 iterations with a learning rate of 0.01.\n",
        "We will start with a random prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18AX7hrU8bv5"
      },
      "source": [
        "lr = 0.01\n",
        "n_iter = 1000\n",
        "\n",
        "y_pred = np.random.randn(2,1)\n",
        "X_b = np.c_[np.ones((len(X), 1)), X]\n",
        "y_pred, cost_history, y_pred_history = gradient_descent(X_b, y, y_pred, lr, n_iter)\n",
        "\n",
        "print('y_pred[0]: {:0.3f}\\ny_pred[1]: {:0.3f}'.format(y_pred[0][0], y_pred[1][0]))\n",
        "print('Final error: {:0.3f}'.format(cost_history[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7fao2MaE216"
      },
      "source": [
        "Plotting the error vs Number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrkrAAbk8hIs"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "ax.set_ylabel('Error')\n",
        "ax.set_xlabel('Number of iterations')\n",
        "\n",
        "ax.plot(range(n_iter), cost_history, 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG5tWAy-FCaW"
      },
      "source": [
        "Zooming in..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ7BoFHy8kTk"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(10,8))\n",
        "ax.plot(range(200), cost_history[:200], 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYhOp3fjnh2G"
      },
      "source": [
        "# Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Batch Gradient Descent we were considering all the examples for every step of Gradient Descent. But what if our dataset is very huge. Deep learning models crave for data. The more the data the more chances of a model to be good. Suppose our dataset has 5 million examples, then just to take one step the model will have to calculate the gradients of all the 5 million examples. This does not seem an efficient way. To tackle this problem we have Stochastic Gradient Descent. In Stochastic Gradient Descent (SGD), we consider just one example at a time to take a single step."
      ],
      "metadata": {
        "id": "10N2dcwWUctJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwD7Cqw8m1d"
      },
      "source": [
        "def stocashtic_gradient_descent(X, y, y_pred, learning_rate=0.01, iterations=10):\n",
        "    '''\n",
        "    X = Matrix of X with added bias units\n",
        "    y = Vector of Y\n",
        "    y_pred = Vector of y_pred np.random.randn(j,1)\n",
        "    learning_rate\n",
        "    iterations = no of iterations\n",
        "\n",
        "    Returns the final y_pred vector and array of cost history over no of iterations\n",
        "    '''\n",
        "\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "\n",
        "    for it in range(iterations):\n",
        "        cost = 0.0\n",
        "\n",
        "        for i in range(m):\n",
        "            rand_ind = np.random.randint(0,m)\n",
        "            X_i = X[rand_ind, :].reshape(1, X.shape[1])\n",
        "            y_i = y[rand_ind].reshape(1,1)\n",
        "            prediction = np.dot(X_i, y_pred)\n",
        "\n",
        "            y_pred = y_pred - (1 / m) * learning_rate *(X_i.T.dot((prediction - y_i)))\n",
        "            cost += cal_cost(y_pred, X_i, y_i)\n",
        "\n",
        "        cost_history[it]  = cost\n",
        "\n",
        "    return y_pred, cost_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk6pfB5c8tPz"
      },
      "source": [
        "lr = 0.5\n",
        "n_iter = 50\n",
        "y_pred = np.random.randn(2, 1)\n",
        "X_b = np.c_[np.ones((len(X), 1)), X]\n",
        "y_pred, cost_history = stocashtic_gradient_descent(X_b, y, y_pred, lr, n_iter)\n",
        "\n",
        "print('y_pred[0]: {:0.3f}\\ny_pred[1]: {:0.3f}'.format(y_pred[0][0], y_pred[1][0]))\n",
        "print('Final error: {:0.3f}'.format(cost_history[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiJUgS7o8u2e"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_ylabel('Error')\n",
        "ax.set_xlabel('Number of iterations')\n",
        "y_pred = np.random.randn(2,1)\n",
        "\n",
        "ax.plot(range(n_iter), cost_history, 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScckWktynk1o"
      },
      "source": [
        "# Mini Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have seen the Batch Gradient Descent. We have also seen the Stochastic Gradient Descent. Batch Gradient Descent can be used for smoother curves. SGD can be used when the dataset is large. Batch Gradient Descent converges directly to minima. SGD converges faster for larger datasets. But, since in SGD we use only one example at a time, we cannot implement the vectorized implementation on it. This can slow down the computations. To tackle this problem, a mixture of Batch Gradient Descent and SGD is used.\n",
        "Neither we use all the dataset all at once nor we use the single example at a time. We use a batch of a fixed number of training examples which is less than the actual dataset and call it a mini-batch. Doing this helps us achieve the advantages of both the former variants we saw."
      ],
      "metadata": {
        "id": "ZTVz-QssUkuE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JtxFVL78wEm"
      },
      "source": [
        "def minibatch_gradient_descent(X, y, y_pred, learning_rate=0.01, iterations=10, batch_size=20):\n",
        "    '''\n",
        "    X = Matrix of X without added bias units\n",
        "    y = Vector of Y\n",
        "    y_pred = Vector of y_preds np.random.randn(j, 1)\n",
        "    learning_rate\n",
        "    iterations = no of iterations\n",
        "\n",
        "    Returns the final theta vector and array of cost history over no of iterations\n",
        "    '''\n",
        "\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "    n_batches = int(m / batch_size)\n",
        "\n",
        "    for it in range(iterations):\n",
        "        cost = 0.0\n",
        "        indices = np.random.permutation(m)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        for i in range(0, m, batch_size):\n",
        "            X_i = X[i: i + batch_size]\n",
        "            y_i = y[i: i + batch_size]\n",
        "\n",
        "            X_i = np.c_[np.ones(len(X_i)), X_i]\n",
        "            prediction = np.dot(X_i, y_pred)\n",
        "\n",
        "            y_pred = y_pred - (1 / m) * learning_rate * (X_i.T.dot((prediction - y_i)))\n",
        "            cost += cal_cost(y_pred, X_i, y_i)\n",
        "\n",
        "        cost_history[it]  = cost\n",
        "\n",
        "    return y_pred, cost_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpbsVwA28znL"
      },
      "source": [
        "lr = 0.1\n",
        "n_iter = 200\n",
        "y_pred = np.random.randn(2,1)\n",
        "y_pred, cost_history = minibatch_gradient_descent(X, y, y_pred, lr, n_iter)\n",
        "\n",
        "print('y_pred[0]: {:0.3f}\\ny_pred[1]: {:0.3f}'.format(y_pred[0][0], y_pred[1][0]))\n",
        "print('Final error: {:0.3f}'.format(cost_history[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ivOYHT817C"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_ylabel('Error')\n",
        "ax.set_xlabel('Number of iterations')\n",
        "y_pred = np.random.randn(2,1)\n",
        "\n",
        "ax.plot(range(n_iter), cost_history, 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to try out:\n",
        "\n",
        "1. Change batch size in mini-batch gradient descent.\n",
        "2. Test all the three out on real datasets.\n",
        "3. Compare the effects of changing learning rate by the same amount in Batch GD, SGD and Mini-batch GD."
      ],
      "metadata": {
        "id": "0neTARjKUoP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Additional Critical Thinking Question**\n",
        "\n"
      ],
      "metadata": {
        "id": "u8BdtVjRdKOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which of the following is TRUE, given the optimal learning rate?**\n",
        "\n",
        " (i) Batch gradient descent is always guaranteed to converge to the global optimum of a loss function.\n",
        "\n",
        " (ii) Stochastic gradient descent is always guaranteed to converge to the global optimum of a loss function.\n",
        "\n",
        " (iii) For convex loss functions (i.e. with a bowl shape), batch gradient descent is guaranteed to eventually converge to the global optimum while stochastic gradient descent is not.\n",
        "\n",
        " (iv) For convex loss functions (i.e. with a bowl shape), stochastic gradient descent is guaranteed to eventually converge to the global optimum while batch gradient descent is not.\n",
        "\n",
        " (v) For convex loss functions (i.e. with a bowl shape), both stochastic gradient descent and batch gradient descent will eventually converge to the global optimum.\n",
        "\n",
        " (vi) For convex loss functions (i.e. with a bowl shape), neither stochastic gradient descent nor batch gradient descent are guaranteed to converge to the global optimum."
      ],
      "metadata": {
        "id": "5XZRrUrffL2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correct answer is:\n",
        "\n",
        "(v) For convex loss functions (i.e., with a bowl shape), both stochastic gradient descent and batch gradient descent will eventually converge to the global optimum.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "1. (i) False: Batch gradient descent minimizes the loss function across the entire dataset at each step. For convex loss functions, it converges to the global optimum, but this is not a general statement for all types of loss functions.\n",
        "\n",
        "\n",
        "2. (ii) False: Stochastic gradient descent (SGD) introduces randomness by updating weights using a single or a small batch of samples, which may lead to oscillations around the global optimum. It is not guaranteed to always converge exactly to the global optimum.\n",
        "\n",
        "\n",
        "3. (iii) False: Batch gradient descent is guaranteed to converge to the global optimum for convex loss functions, while SGD may also converge but with potential oscillations or slower convergence depending on hyperparameter tuning.\n",
        "\n",
        "\n",
        "4. (iv) False: SGD can converge to the global optimum of convex loss functions, but batch gradient descent is also guaranteed to converge. The statement implies exclusivity, which is incorrect.\n",
        "\n",
        "\n",
        "5. (v) True: Both methods are guaranteed to converge to the global optimum for convex loss functions if the learning rate is chosen appropriately (e.g., by using a diminishing learning rate for SGD).\n",
        "\n",
        "\n",
        "6. (vi) False: For convex loss functions, convergence is guaranteed with proper conditions, so neither method can be dismissed.\n",
        "\n",
        "\n",
        "\n",
        "In summary, (v) is the most accurate statement."
      ],
      "metadata": {
        "id": "mBwnd9OIeSwY"
      }
    }
  ]
}